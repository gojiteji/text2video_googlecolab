{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM0dVZFdjjpLaosEdptW2bK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gojiteji/text2video_googlecolab/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRaU43dpS8Wu",
        "outputId": "10298673-6c75-42ee-aee2-86dcc463637c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'Text2Video-Zero'...\n",
            "remote: Enumerating objects: 758, done.\u001b[K\n",
            "remote: Counting objects: 100% (758/758), done.\u001b[K\n",
            "remote: Compressing objects: 100% (701/701), done.\u001b[K\n",
            "remote: Total 758 (delta 190), reused 509 (delta 50), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (758/758), 493.57 KiB | 2.64 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n",
            "Filtering content: 100% (127/127), 409.86 MiB | 40.62 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/spaces/PAIR/Text2Video-Zero"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.16.0\\\n",
        "addict==2.4.0 \\\n",
        "albumentations==1.3.0\\\n",
        "basicsr==1.4.2\\\n",
        "decord==0.6.0\\\n",
        "diffusers==0.14.0\\\n",
        "einops==0.6.0\\\n",
        "gradio==3.23.0\\\n",
        "kornia==0.6\\\n",
        "imageio==2.9.0\\\n",
        "imageio-ffmpeg==0.4.2\\\n",
        "invisible-watermark>=0.1.5\\\n",
        "moviepy==1.0.3\\\n",
        "numpy==1.24.1\\\n",
        "omegaconf==2.3.0\\\n",
        "open_clip_torch==2.16.0\\\n",
        "opencv_python==4.7.0.68\\\n",
        "opencv-contrib-python\\\n",
        "Pillow==9.4.0\\\n",
        "pytorch_lightning==1.5.0\\\n",
        "prettytable==3.6.0\\\n",
        "scikit_image==0.19.3\\\n",
        "scipy==1.10.1\\\n",
        "tensorboardX==2.6\\\n",
        "tqdm==4.64.1\\\n",
        "timm==0.6.12\\\n",
        "transformers==4.26.0\\\n",
        "test-tube>=0.7.5\\\n",
        "webdataset==0.2.5\\\n",
        "yapf==0.32.0\\\n",
        "safetensors==0.2.7\\\n",
        "huggingface-hub==0.13.0\\\n",
        "torch==1.13.1\\\n",
        "torchvision==0.14.1"
      ],
      "metadata": {
        "id": "ZAAV1PenTaO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change demo.launch(debug=True,share=True)\n",
        "!cd Text2Video-Zero && python3 app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXJFcHMS-YA",
        "outputId": "9c425288-e652-4949-c970-125707be9084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-29 17:34:37.394480: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-29 17:34:37.598050: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-29 17:34:38.433601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-29 17:34:38.433702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-29 17:34:38.433721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/usr/local/lib/python3.9/dist-packages/flax/core/frozen_dict.py:169: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(\n",
            "cuda\n",
            "cuda\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/helpers.py:215: UserWarning: Examples are being cached but not all input components have example values. This may result in an exception being thrown by your function. If you do get an error while caching examples, make sure all of your inputs have example values for all of your examples or you provide default values for those particular parameters in your function.\n",
            "  warnings.warn(\n",
            "Using cache from '/content/Text2Video-Zero/gradio_cached_examples/21' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/helpers.py:215: UserWarning: Examples are being cached but not all input components have example values. This may result in an exception being thrown by your function. If you do get an error while caching examples, make sure all of your inputs have example values for all of your examples or you provide default values for those particular parameters in your function.\n",
            "  warnings.warn(\n",
            "Using cache from '/content/Text2Video-Zero/gradio_cached_examples/44' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "Using cache from '/content/Text2Video-Zero/gradio_cached_examples/63' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "Using cache from '/content/Text2Video-Zero/gradio_cached_examples/79' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "Using cache from '/content/Text2Video-Zero/gradio_cached_examples/104' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://7e81ddb2473a5f3aeb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "Fetching 15 files: 100% 15/15 [00:00<00:00, 57403.80it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "You have disabled the safety checker for <class 'text_to_video.text_to_video_pipeline.TextToVideoPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "12 12\n",
            " Use: Motion field = True\n",
            " Use: Background smoothing = False\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 0, t = 981, latent = torch.Size([1, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            "  2% 1/50 [00:01<01:13,  1.50s/it]latent t1 found at i=1, t = 961\n",
            "  6% 3/50 [00:01<00:20,  2.29it/s]latent t0 found at i = 4, t = 901\n",
            "100% 50/50 [00:04<00:00, 11.27it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 2, t = 941, latent = torch.Size([8, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            " 96% 48/50 [00:09<00:00,  5.10it/s]\n",
            "Frame spit shape torch.Size([1, 4, 8, 64, 64])\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "12 12\n",
            " Use: Motion field = True\n",
            " Use: Background smoothing = False\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 0, t = 981, latent = torch.Size([1, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            "latent t1 found at i=1, t = 961\n",
            "  8% 4/50 [00:00<00:02, 15.68it/s]latent t0 found at i = 4, t = 901\n",
            "100% 50/50 [00:03<00:00, 16.36it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 2, t = 941, latent = torch.Size([8, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            " 96% 48/50 [00:09<00:00,  5.11it/s]\n",
            "Frame spit shape torch.Size([1, 4, 8, 64, 64])\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "12 12\n",
            " Use: Motion field = True\n",
            " Use: Background smoothing = False\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 0, t = 981, latent = torch.Size([1, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            "latent t1 found at i=1, t = 961\n",
            "  8% 4/50 [00:00<00:03, 15.32it/s]latent t0 found at i = 4, t = 901\n",
            "100% 50/50 [00:03<00:00, 16.47it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 2, t = 941, latent = torch.Size([8, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            " 96% 48/50 [00:09<00:00,  5.12it/s]\n",
            "Frame spit shape torch.Size([1, 4, 8, 64, 64])\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "12 12\n",
            " Use: Motion field = True\n",
            " Use: Background smoothing = False\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 0, t = 981, latent = torch.Size([1, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            "latent t1 found at i=1, t = 961\n",
            "  8% 4/50 [00:00<00:02, 15.72it/s]latent t0 found at i = 4, t = 901\n",
            "100% 50/50 [00:03<00:00, 16.46it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 2, t = 941, latent = torch.Size([8, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            " 96% 48/50 [00:09<00:00,  5.11it/s]\n",
            "Frame spit shape torch.Size([1, 4, 8, 64, 64])\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "12 12\n",
            " Use: Motion field = True\n",
            " Use: Background smoothing = False\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 0, t = 981, latent = torch.Size([1, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            "latent t1 found at i=1, t = 961\n",
            "  8% 4/50 [00:00<00:02, 15.80it/s]latent t0 found at i = 4, t = 901\n",
            "100% 50/50 [00:03<00:00, 16.45it/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "  0% 0/50 [00:00<?, ?it/s]Continue DDIM with i = 2, t = 941, latent = torch.Size([8, 4, 64, 64]), device = cuda:0, type = torch.float16\n",
            " 96% 48/50 [00:09<00:00,  5.12it/s]\n",
            "Frame spit shape torch.Size([1, 4, 8, 64, 64])\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n",
            "frame decoding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FcwlC7PATVeV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}